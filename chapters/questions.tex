\section{Describe the general characteristics of a scheduling for real-time, possibly including a comparison between Rate Monotonic and EDF. }

\section{Describe the main algorithms for the scheduling of a single-core CPU, paying particular attention to the possible overhead, fairness and reactivity.}

\section{ Detail the boot process of a microcontroller running a C++ bare metal application, from the reset vector to main(). What are the differences compared to a C program.  }


\section{Describe the general characteristics and figures of merit of a CPU scheduler and those more related to the case of Real Time Operating Systems}


\section{Describe the ARM Cortex-M processor by detailing its main features, its registers and the organization and functional principle of the vector table. Extra: What is the CMSIS and which are its main purposes?  }

Q1 See presentation ARM Processors and Architectures - Introduction and Programmer's Model

\section{Describe how interrupts work, detailing the difference between a simple interrupt and one where a context switch occurs.}
Interrupts provide a way to interrupt the normal program flow of the CPU  to handle events generated by peripherals without the expense of polling. A contex switch implies an operating system. In a bare metal embedded device without operating system, no context switch exist. In this case, the interrupt interrupts the execution of the main code (i.e, of the main() function or of a function who is in the call stack of main()). When there is no context switch, the only registers that need to be saved are the ones used by the interrupt service routine (ISR), because at the end of the ISR the code execution will return to the main code, which can be thought of as the only task in the system. This register saving is often done by the compiler. 
This is the timeline:  
++ main code | ISR | main code ++> Time

When you add an OS, an interrupt can wake up a higher priority task than the currently running one (or the time quantum of the task can be expired). So, the task that is running at the end of the interrupt may not be the same as the one running before, as in this timeline: 


++ task1 | ISR | task2 ++> Time


Since each task has its set of registers, upon entering the ISR all registers have to be stored in a perÂ­task data structure within the OS, called a task control block. This is because the registers that will be restored at the end of the ISR will be those of the next task, which may or may not be the one that was interrupted. Not saving all of them (or not restoring all of them) does not work when the before and after task differ. This saving is done by code in the OS, not by the compiler.

\section{What is a linker script? Describe its purpose and give an overview of the content of a typical linker script.}
The linker script is a file that's used at the final part of the building process. It is used to place in memory the various section contents of the object files. 
The typical content of simplest Linker Script (written in linker language) is composed by SECTIONS\{\}.
In the SECTIONS, one can map the three (or more) parts of the obj file, namely:
\begin{itemize}
	\item \code{.text}, that contains the instructions
	\item \code{.data}, that contains the initialized data
	\item \code{.bss}, (Block Started by Symbols) that contains the non-initialized and zero-initialized data
\end{itemize}


\section{Describe the Earliest Deadline First and Rate Monotonic Scheduling, making also a comparison to put in evidence limits and range of applicability.}

Both algorithms are good to schedule recurrent tasks.

EDF is a scheduling algorithm that every time a new task gets to the ready queue, calculates which task it's closer to the deadline and gives it the priority, making it run until completion or if a closer-to-schedule task preempts it when it gets in the ready queue. 
RM is, on the other hand, a scheduling algorithm that has fixed priorities for every task and the one that gets highest priority is the most recurrent one.

EDF has more CPU time occupation than RM, but if it gets overloaded there's no way to know which tasks will get priority: this is the reason why this algorithm is unsuitable for industrial applications. Moreover, the calculation of the next closest deadline may take some time and overhead the system.

RM hardly gets always a 100\% busy CPU, but if it gets overloaded, higher priority tasks will be the favourited, thereby reaching successfully completing before the deadline.

\section{Describe the main algorithms for the scheduling of a single-core CPU, paying particular attention to the possible overhead, fairness and reactivity.}

Scheduling algorithms try to optimize different key factors, with the aim of running multiple tasks sequently, as they were run at the same time.
These key factors, on which the schedulers are optimized, may be:
\begin{itemize}
	\item CPU utilization
	\item Fairness
	\item Reactivity
	\item Responsiveness
	\item other...
\end{itemize}

Ovbiously, one cannot optimize for a key factor without accepting compromises on others: for this reason there is no perfect algorithm, just the most suitable for each application.

Each algorithm can also have different features, depending on the needs of the system. They could be:
\begin{itemize}
	\item Preemptive or not preemptive
	\item With fixed priority or not
	\item With multiple queues or not
\end{itemize}

The main algorithms for scheduling, non real-time on a single-core CPU are:
\begin{itemize}
	\item First-come-First served: it's easily implemented, quite fair if there are no blocking tasks, with low overhead but also low reactivity.
	\item Round-Robin: It switches continuously (in a pre-defined time-base) between every task in the ready queue, it's highly fair a discretely reactive, but with high overhead. Eventually, longer tasks may take a lot to finish, due to the continuous interruptions.
	\item Shortest Job First: it has some overhead in calculating the shortest job (and it does not work correctly in the first transient, while the recurrent task have been started just once or a couple of times). It's not fair with longer tasks and reactive only if it implements preemption.
	\item Feedback: penalizes jobs that have been running longer, it's highly fair because starvation cannot occur, but the overhead of calculating the highest priority task can be high and the responsiveness is low, if there are a lot of tasks.
	\item Fair share: it divides the run queue in various fixed sub-queues, to which a fair-share of 100\% CPU time is assigned. This algorithm is fair but it may waste some CPU time. 
	\item Higher Response Ratio Next: it's like a shortest job first, but is weighted with the queue wait time; if a task is not short but it's waiting for a long time, it will access the CPU anyway. It's a fair algorithm and has some overhead. Reaction depends whether or not a fixed priority with preemption is implemented.
\end{itemize}

